{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea205720",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "# 2.5.3 Files\n",
    "df_path_abun = pd.read_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/pathways_out/path_abun_contrib.tsv', sep='\\t', dtype=str, header=0, usecols=['sample', 'function', 'taxon', 'taxon_abun', 'taxon_function_abun'])\n",
    "df_path_abun_unstrat = pd.read_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_unstratified/picrust2_out_pipeline_lasse/pathways_out/path_abun_unstrat.tsv', sep='\\t', dtype=str, header=0)\n",
    "df_tax = pd.read_csv('~/Thesis/data/tax_complete_qiime.txt', sep='\\t', dtype=str, header=None, names=['taxon', 'taxonomy'])\n",
    "df_meta = pd.read_csv('~/Thesis/data/metadata.txt', sep='\\t', dtype=str, header=0, usecols=['Barcode ', 'ReactorID', 'SampleDate'])\n",
    "df_nsti = pd.read_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/KO_metagenome_out/weighted_nsti.tsv', sep='\\t', dtype=str, header=0)\n",
    "df_asv_nsti = pd.read_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/marker_predicted_and_nsti.tsv', sep='\\t', dtype=str, header=0, usecols=['sequence', 'metadata_NSTI'])   \n",
    "\n",
    "# 2.6.2 Files\n",
    "df_sc_path_abun = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/2.6.2_strat_out/pathways_out/path_abun_contrib.tsv', sep='\\t', dtype=str, header=0, usecols=['sample', 'function', 'taxon', 'taxon_abun', 'taxon_function_abun'])\n",
    "df_sc_path_abun_unstrat = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/2.6.2_strat_out/pathways_out/path_abun_unstrat.tsv', sep='\\t', dtype=str, header=0)\n",
    "df_sc_nsti = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/2.6.2_strat_out/KO_metagenome_out/weighted_nsti.tsv', sep='\\t', dtype=str, header=0)\n",
    "df_sc_asv_nsti = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/2.6.2_strat_out/combined_marker_predicted_and_nsti.tsv', sep='\\t', dtype=str, header=0, usecols=['sequence', 'metadata_NSTI', 'best_domain'])   \n",
    "\n",
    "# 2.6.2 model data files\n",
    "df_nsti = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/model_data/KO_metagenome_out/weighted_nsti.tsv', sep='\\t', dtype=str, header=0)\n",
    "\n",
    "# Remove invisible spacings\n",
    "for df in [df_path_abun, df_path_abun_unstrat, df_tax, df_meta, df_nsti, df_asv_nsti, \n",
    "           df_sc_path_abun, df_sc_path_abun_unstrat, df_sc_nsti, df_sc_asv_nsti]:\n",
    "    df.columns = df.columns.str.strip() # Strip whitespace from column headers\n",
    "    for col in ['sample', 'function', 'taxon', 'pathway', 'taxonomy', \n",
    "                'Barcode', 'ReactorID', 'SampleDate', 'sequence', 'best_domain']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].str.strip() # Strip whitespace from relevant string columns if they exist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac450554",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save files\n",
    "df_path_abun.to_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/temp_diff/df_path_abun.tsv', sep='\\t', index=False)\n",
    "df_tax.to_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/temp_diff/df_tax.tsv', sep='\\t', index=False)\n",
    "df_meta.to_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/temp_diff/df_meta.tsv', sep='\\t', index=False)\n",
    "df_nsti.to_csv('~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/temp_diff/df_nsti.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f640624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for PR1 and PR4\n",
    "barcodes = df_meta[df_meta['ReactorID'].isin(['PR1', 'PR4'])]['Barcode'].tolist()\n",
    "df_path_abun = df_path_abun[df_path_abun['sample'].isin(barcodes)].copy()\n",
    "df_sc_path_abun = df_sc_path_abun[df_sc_path_abun['sample'].isin(barcodes)].copy()\n",
    "\n",
    "PR1 = df_meta[df_meta['ReactorID'].isin(['PR1'])]['Barcode'].tolist()\n",
    "PR4 = df_meta[df_meta['ReactorID'].isin(['PR4'])]['Barcode'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5122ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sc_nsti.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weighted NSTI distribution\n",
    "\n",
    "## 2.5.3 DATA\n",
    "# Numeric values\n",
    "df_nsti['weighted_NSTI'] = pd.to_numeric(df_nsti['weighted_NSTI'], errors='coerce').copy()\n",
    "\n",
    "# Boolean masks for PR1 and PR4\n",
    "mask_pr1 = df_nsti['sample'].isin(PR1)\n",
    "mask_pr4 = df_nsti['sample'].isin(PR4)\n",
    "\n",
    "# Bins\n",
    "all_vals = df_nsti.loc[mask_pr1 | mask_pr4, 'weighted_NSTI'].dropna().values\n",
    "bins = np.histogram_bin_edges(all_vals, bins='auto') if len(all_vals) else 20\n",
    "\n",
    "# Histogram of weighted NSTI values\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(df_nsti.loc[mask_pr1, 'weighted_NSTI'].dropna(), bins=bins, alpha=0.6, label='PR1', density=False)\n",
    "plt.hist(df_nsti.loc[mask_pr4, 'weighted_NSTI'].dropna(), bins=bins, alpha=0.6, label='PR4', density=False)\n",
    "plt.xlabel('Weighted NSTI')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Weighted NSTI distribution, by reactor (2.5.3)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## 2.6.2 DATA\n",
    "# Numeric values\n",
    "df_sc_nsti['weighted_NSTI'] = pd.to_numeric(df_sc_nsti['weighted_NSTI'], errors='coerce').copy()\n",
    "\n",
    "# Boolean masks for PR1 and PR4\n",
    "mask_pr1 = df_sc_nsti['sample'].isin(PR1)\n",
    "mask_pr4 = df_sc_nsti['sample'].isin(PR4)\n",
    "\n",
    "# Bins\n",
    "all_vals = df_nsti.loc[mask_pr1 | mask_pr4, 'weighted_NSTI'].dropna().values\n",
    "bins = np.histogram_bin_edges(all_vals, bins='auto') if len(all_vals) else 20\n",
    "\n",
    "# Histogram of weighted NSTI values\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.hist(df_sc_nsti.loc[mask_pr1, 'weighted_NSTI'].dropna(), bins=bins, alpha=0.6, label='PR1', density=False)\n",
    "plt.hist(df_sc_nsti.loc[mask_pr4, 'weighted_NSTI'].dropna(), bins=bins, alpha=0.6, label='PR4', density=False)\n",
    "plt.xlabel('Weighted NSTI')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Weighted NSTI distribution, by reactor (2.6.2)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c814d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparison of weighted NSTI means (model data reference)\n",
    "\n",
    "## 2.5.3\n",
    "# Data\n",
    "df_nsti_model = pd.read_csv('~/Thesis/data/picrust2_testruns/2.5.3/model_data/picrust2_out_pipeline_stratified/KO_metagenome_out/weighted_nsti.tsv', sep='\\t', dtype=str, header=0)\n",
    "\n",
    "# Numeric values\n",
    "df_nsti['weighted_NSTI'] = pd.to_numeric(df_nsti['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "df_nsti['weighted_NSTI'] = pd.to_numeric(df_nsti['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "df_nsti_model['weighted_NSTI'] = pd.to_numeric(df_nsti_model['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "\n",
    "# Mean NSTI for PR1 samples\n",
    "mean_PR1 = df_nsti.loc[df_nsti['sample'].isin(PR1), 'weighted_NSTI'].mean()\n",
    "\n",
    "# Mean NSTI for PR4 samples\n",
    "mean_PR4 = df_nsti.loc[df_nsti['sample'].isin(PR4), 'weighted_NSTI'].mean()\n",
    "\n",
    "# Mean NSTI for model group\n",
    "mean_model = df_nsti_model['weighted_NSTI'].mean()\n",
    "\n",
    "# Print all three neatly\n",
    "print(f\"2.5.3: Mean weighted NSTI (PR1):   {mean_PR1:.4f}\")\n",
    "print(f\"2.5.3: Mean weighted NSTI (PR4):   {mean_PR4:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "## 2.6.2\n",
    "# Loading model data\n",
    "df_nsti_model_sc = pd.read_csv('~/Thesis/data/picrust2_testruns/2.6.2/model_data/KO_metagenome_out/weighted_nsti.tsv', sep='\\t', dtype=str, header=0)\n",
    "\n",
    "# Numeric values\n",
    "df_sc_nsti['weighted_NSTI'] = pd.to_numeric(df_sc_nsti['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "df_sc_nsti['weighted_NSTI'] = pd.to_numeric(df_sc_nsti['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "df_nsti_model_sc['weighted_NSTI'] = pd.to_numeric(df_nsti_model_sc['weighted_NSTI'], errors='coerce').fillna(0.0)\n",
    "\n",
    "\n",
    "# Mean NSTI for PR1 samples\n",
    "mean_sc_PR1 = df_sc_nsti.loc[df_sc_nsti['sample'].isin(PR1), 'weighted_NSTI'].mean()\n",
    "\n",
    "# Mean NSTI for PR4 samples\n",
    "mean_sc_PR4 = df_sc_nsti.loc[df_sc_nsti['sample'].isin(PR4), 'weighted_NSTI'].mean()\n",
    "\n",
    "# Mean NSTI for model group\n",
    "mean_model_sc = df_nsti_model_sc['weighted_NSTI'].mean()\n",
    "\n",
    "\n",
    "# Print all three neatly\n",
    "print(f\"2.6.2: Mean weighted NSTI (PR1):   {mean_sc_PR1:.4f}\")\n",
    "print(f\"2.6.2: Mean weighted NSTI (PR4):   {mean_sc_PR4:.4f}\")\n",
    "\n",
    "print(f\"2.5.3: Mean weighted NSTI (model): {mean_model:.4f}\")\n",
    "print(f\"2.5.3: Mean weighted NSTI (model): {mean_model:.4f}\")\n",
    "print(f\"2.6.2: Mean weighted NSTI (model): {mean_model_sc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b239a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Genus-level pathway contributions for PR1 and PR4\n",
    "\n",
    "\n",
    "# (1) Define pathways of interest\n",
    "pathways = ['METH-ACETATE-PWY',\n",
    "            'METHANOGENESIS-PWY']\n",
    "\n",
    "\n",
    "# (2) Define df, select required columns\n",
    "df = df_path_abun[['sample', 'function', 'taxon', 'taxon_function_abun']].copy()\n",
    "\n",
    "\n",
    "# (3) Numeric values\n",
    "df['taxon_function_abun'] = pd.to_numeric(df['taxon_function_abun'], errors='coerce').fillna(0.0)\n",
    "\n",
    "\n",
    "# (4) Normalise taxonomy table whitespace\n",
    "df_tax[\"taxon\"] = df_tax[\"taxon\"].str.strip()\n",
    "df_tax[\"taxonomy\"] = df_tax[\"taxonomy\"].str.strip()\n",
    "\n",
    "\n",
    "# (5) Merge taxonomy on stratified abundance table\n",
    "df = df.merge(df_tax, on='taxon', how='left').copy()\n",
    "\n",
    "\n",
    "# (6) Create dictionary for rank extraction\n",
    "ranks = {\n",
    "    \"kingdom\": \"k__\", \"phylum\": \"p__\", \"class\": \"c__\", \"order\": \"o__\",\n",
    "    \"family\": \"f__\", \"genus\": \"g__\", \"species\": \"s__\"\n",
    "}\n",
    "\n",
    "\n",
    "# (7) Parse rank names out of taxonomy string\n",
    "for col, prefix in ranks.items():\n",
    "    df[col] = df[\"taxonomy\"].str.extract(fr\"{prefix}\\s*([^;]+)\", expand=False).str.strip()\n",
    "\n",
    "\n",
    "# (8) Collapse ASV-level pathway abundances to genus-level for PR1\n",
    "PR1_abun_genus = (\n",
    "    df[df[\"sample\"].isin(PR1)]\n",
    "      .groupby([\"function\", \"genus\"], as_index=False)[\"taxon_function_abun\"]\n",
    "      .sum()\n",
    "      .rename(columns={\"taxon_function_abun\": \"total_contribution\"})\n",
    ")\n",
    "\n",
    "# (9) Collapse ASV-level pathway abundances to genus-level for PR4\n",
    "PR4_abun_genus = (\n",
    "    df[df[\"sample\"].isin(PR4)]\n",
    "      .groupby([\"function\", \"genus\"], as_index=False)[\"taxon_function_abun\"]\n",
    "      .sum()\n",
    "      .rename(columns={\"taxon_function_abun\": \"total_contribution\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdd79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taxonomy-weighted and unweighted NSTI by genus and domain\n",
    "\n",
    "\n",
    "# (1) Harmonise and merge NSTIs onto asv_taxon (each ASV now has its NSTI and taxonomy)\n",
    "df_asv_nsti = df_asv_nsti.rename(columns={\"sequence\":\"taxon\", \"metadata_NSTI\":\"NSTI\"}).copy()\n",
    "asv_taxon = df_asv_nsti.merge(df_tax, on=\"taxon\", how=\"left\")\n",
    "\n",
    "# (2) Extract domain-level, genus-level, and species-level rows\n",
    "asv_taxon[\"genus\"] = (asv_taxon[\"taxonomy\"].astype(str)\n",
    "                      .str.extract(r\"g__\\s*([^;]+)\", expand=False).str.strip())\n",
    "asv_taxon[\"domain\"] = (asv_taxon[\"taxonomy\"].astype(str)\n",
    "                       .str.extract(r\"k__\\s*([^;]+)\", expand=False).str.strip())\n",
    "asv_taxon[\"species\"] = (asv_taxon[\"taxonomy\"].astype(str)\n",
    "                       .str.extract(r\"s__\\s*([^;]+)\", expand=False).str.strip())\n",
    "\n",
    "# (3) Ensure numeric NSTI and keep rows with both NSTI and chosen rank present\n",
    "asv_taxon[\"NSTI\"] = pd.to_numeric(asv_taxon[\"NSTI\"], errors=\"coerce\")\n",
    "asv_taxon_genus  = asv_taxon.dropna(subset=[\"NSTI\",\"genus\"])\n",
    "asv_taxon_domain = asv_taxon.dropna(subset=[\"NSTI\",\"domain\"])\n",
    "\n",
    "# (4) Collapse NSTI values to genus-level\n",
    "genus_nsti = (\n",
    "    asv_taxon_genus.groupby(\"genus\")[\"NSTI\"]\n",
    "                   .agg(mean_NSTI=\"mean\", median_NSTI=\"median\", n_ASVs=\"size\")\n",
    "                   .reset_index()\n",
    ")\n",
    "\n",
    "# (5) Load per-sample ASV relative abundances to build weighting\n",
    "abun = pd.read_csv(\"~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/picrust2_out_pipeline_stratified_lasse/KO_metagenome_out/seqtab_norm.tsv\", sep=\"\\t\")\n",
    "abun = abun.rename(columns={abun.columns[0]: \"taxon\"})\n",
    "abun_long = abun.melt(id_vars=[\"taxon\"], var_name=\"sample\", value_name=\"rel_abun\")\n",
    "abun_long[\"rel_abun\"] = pd.to_numeric(abun_long[\"rel_abun\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# (6) Collapse sample weights to a single weight per ASV\n",
    "asv_weight = (abun_long.groupby(\"taxon\")[\"rel_abun\"].mean()\n",
    "                        .reset_index().rename(columns={\"rel_abun\":\"mean_rel_abun\"}))\n",
    "\n",
    "# (7) Genus-level weighted NSTI: abundance-weighted community perspective\n",
    "asv_taxon_genus_w = (asv_taxon_genus.merge(asv_weight, on=\"taxon\", how=\"left\")\n",
    "                                    .fillna({\"mean_rel_abun\":0}))\n",
    "\n",
    "genus_nsti_weighted = (\n",
    "    asv_taxon_genus_w.groupby(\"genus\")\n",
    "                     .apply(lambda d: np.average(d[\"NSTI\"], weights=d[\"mean_rel_abun\"])\n",
    "                            if d[\"mean_rel_abun\"].sum() > 0 else d[\"NSTI\"].mean())\n",
    "                     .reset_index(name=\"weighted_mean_NSTI\")\n",
    ")\n",
    "\n",
    "# (8) Domain-level weighted NSTI (same approach)\n",
    "asv_taxon_domain_w = (asv_taxon_domain.merge(asv_weight, on=\"taxon\", how=\"left\")\n",
    "                                      .fillna({\"mean_rel_abun\":0}))\n",
    "\n",
    "domain_nsti_weighted = (\n",
    "    asv_taxon_domain_w.groupby(\"domain\")\n",
    "                      .apply(lambda d: np.average(d[\"NSTI\"], weights=d[\"mean_rel_abun\"])\n",
    "                             if d[\"mean_rel_abun\"].sum() > 0 else d[\"NSTI\"].mean())\n",
    "                      .reset_index(name=\"weighted_mean_NSTI\")\n",
    ")\n",
    "\n",
    "# (9) Visualise domain-level weighted NSTI\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.bar(domain_nsti_weighted[\"domain\"], domain_nsti_weighted[\"weighted_mean_NSTI\"], color=\"steelblue\")\n",
    "plt.ylabel(\"Mean weighted NSTI\")\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.title(\"Mean weighted NSTI by domain\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (10) Summary of exact mean weighted NSTI values\n",
    "print(domain_nsti_weighted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67227b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## good: < 0.06\n",
    "## high: > 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Genus-level comparison of pathway abundances between PR1 and PR4\n",
    "\n",
    "\n",
    "\n",
    "## Acetoclastic methanogenesis ##\n",
    "\n",
    "# (1) Genus level pathway abundance for acetoclastic methanogenesis\n",
    "PR1_sub_ace = PR1_abun_genus[PR1_abun_genus['function'] == 'METH-ACETATE-PWY'].copy()\n",
    "PR4_sub_ace = PR4_abun_genus[PR4_abun_genus['function'] == 'METH-ACETATE-PWY'].copy()\n",
    "\n",
    "\n",
    "# (2) Ensure the two columns exist and are numeric\n",
    "merged_ace = PR1_sub_ace.merge(PR4_sub_ace, on='genus', how='outer',\n",
    "                       suffixes=('_PR1','_PR4')).fillna(0)\n",
    "for c in ['total_contribution_PR1','total_contribution_PR4']:\n",
    "    merged_ace[c] = pd.to_numeric(merged_ace[c], errors='coerce').fillna(0)\n",
    "\n",
    "\n",
    "# (3) Scatterplot\n",
    "plt.figure(figsize=(6,6))\n",
    "x = merged_ace['total_contribution_PR1'].to_numpy()\n",
    "y = merged_ace['total_contribution_PR4'].to_numpy()\n",
    "top = merged_ace.nlargest(2, ['total_contribution_PR1', 'total_contribution_PR4']).copy()\n",
    "for i, g in top.iterrows():\n",
    "    plt.text(g['total_contribution_PR1'], g['total_contribution_PR4'], g['genus'], fontsize=8, alpha=0.8)\n",
    "plt.scatter(x, y, alpha=0.6, s=20)\n",
    "m = np.nanmax(np.concatenate([x, y]))  # numeric max only\n",
    "plt.plot([0, m], [0, m], 'k--', linewidth=1)  # 1:1 diagonal\n",
    "plt.xlabel('PR1 total contribution')\n",
    "plt.ylabel('PR4 total contribution')\n",
    "plt.title('Genus-level pathway abundance of METH-ACETATE-PWY for PR1 vs PR4')\n",
    "plt.axis('equal'); plt.xlim(0, 55000); plt.ylim(0, 40000)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Hydrogenotrophic methanogenesis ##\n",
    "\n",
    "# (4) Genus level pathway abundance for hydrogenotrophic methanogenesis\n",
    "PR1_sub_hyd = PR1_abun_genus[PR1_abun_genus['function'] == 'METHANOGENESIS-PWY'].copy()\n",
    "PR4_sub_hyd = PR4_abun_genus[PR4_abun_genus['function'] == 'METHANOGENESIS-PWY'].copy()\n",
    "\n",
    "\n",
    "# (5) Ensure the two columns exist and are numeric\n",
    "merged_hyd = PR1_sub_hyd.merge(PR4_sub_hyd, on='genus', how='outer',\n",
    "                       suffixes=('_PR1','_PR4')).fillna(0)\n",
    "for c in ['total_contribution_PR1','total_contribution_PR4']:\n",
    "    merged_hyd[c] = pd.to_numeric(merged_hyd[c], errors='coerce').fillna(0)\n",
    "\n",
    "\n",
    "# (6) Scatterplot\n",
    "plt.figure(figsize=(6,6))\n",
    "x = merged_hyd['total_contribution_PR1'].to_numpy()\n",
    "y = merged_hyd['total_contribution_PR4'].to_numpy()\n",
    "top = merged_hyd.nlargest(2, ['total_contribution_PR1', 'total_contribution_PR4']).copy()\n",
    "for i, g in top.iterrows():\n",
    "    plt.text(g['total_contribution_PR1'], g['total_contribution_PR4'], g['genus'], fontsize=8, alpha=0.8)\n",
    "plt.scatter(x, y, alpha=0.6, s=20)\n",
    "m = np.nanmax(np.concatenate([x, y]))  # numeric max only\n",
    "plt.plot([0, m], [0, m], 'k--', linewidth=1)  # 1:1 diagonal\n",
    "plt.xlabel('PR1 total contribution')\n",
    "plt.ylabel('PR4 total contribution')\n",
    "plt.title('Genus-level pathway abundance of METHANOGENESIS-PWY for PR1 vs PR4')\n",
    "plt.axis('equal'); plt.xlim(0, m); plt.ylim(0, m)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Top contributing genera for METH-ACETATE-PWY and METHANOGENESIS-PWY\n",
    "\n",
    "top15_PR1_ace = PR1_sub_ace.sort_values('total_contribution', ascending=False).head(15).copy()\n",
    "top15_PR4_ace = PR4_sub_ace.sort_values('total_contribution', ascending=False).head(15).copy()\n",
    "top15_PR1_hyd = PR1_sub_hyd.sort_values('total_contribution', ascending=False).head(15).copy()\n",
    "top15_PR4_hyd = PR4_sub_hyd.sort_values('total_contribution', ascending=False).head(15).copy()\n",
    "\n",
    "\n",
    "print('The top 15 contributing genera for acetoclastic methanogenesis in PR1 are ' + ', '.join(top15_PR1_ace['genus'].tolist()))\n",
    "print('The top 15 contributing genera for acetoclastic methanogenesis in PR4 are ' + ', '.join(top15_PR4_ace['genus'].tolist()))\n",
    "print('The top 15 contributing genera for hydrogenotrophic methanogenesis in PR1 are ' + ', '.join(top15_PR1_hyd['genus'].tolist()))\n",
    "print('The top 15 contributing genera for hydrogenotrophic methanogenesis in PR4 are ' + ', '.join(top15_PR4_hyd['genus'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Filter and extract species\n",
    "sub = df[(df['genus'] == 'Methanoculleus') & (df['function'] == 'METHANOGENESIS-PWY')].copy()\n",
    "sub['taxon_function_abun'] = pd.to_numeric(sub['taxon_function_abun'], errors='coerce').fillna(0)\n",
    "sub['species'] = (sub['taxonomy'].astype(str)\n",
    "                  .str.extract(r\"s__\\s*([^;]+)\", expand=False)\n",
    "                  .fillna('unclassified').str.strip())\n",
    "\n",
    "# (2) Per-species sums\n",
    "df_pr1 = (sub[sub['sample'].isin(PR1)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR1'}))\n",
    "df_pr4 = (sub[sub['sample'].isin(PR4)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR4'}))\n",
    "\n",
    "# (3) Merge and prepare\n",
    "merged = pd.merge(df_pr1, df_pr4, on='species', how='outer').fillna(0)\n",
    "merged['total'] = merged['species_contribution_PR1'] + merged['species_contribution_PR4']\n",
    "\n",
    "# (4) Plot\n",
    "x = merged['species_contribution_PR1'].to_numpy()\n",
    "y = merged['species_contribution_PR4'].to_numpy()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x, y, alpha=0.6, s=30)\n",
    "m = float(np.nanmax(np.r_[x, y, 1e-12]))\n",
    "plt.plot([0, m], [0, m], 'k--', linewidth=1)\n",
    "\n",
    "# Label top 3 species by total contribution\n",
    "top3 = merged.nlargest(3, 'total')\n",
    "for _, row in top3.iterrows():\n",
    "    plt.text(row['species_contribution_PR1'], row['species_contribution_PR4'],\n",
    "             row['species'], fontsize=9, alpha=0.8, ha='left', va='bottom')\n",
    "\n",
    "plt.xlabel('PR1 species contribution')\n",
    "plt.ylabel('PR4 species contribution')\n",
    "plt.title('Species-level METHANOGENESIS-PWY: PR1 vs PR4 (Methanoculleus)')\n",
    "plt.axis('equal'); plt.xlim(0, m); plt.ylim(0, m)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Species-level comparative, contributional pathway abundance for Syntrophaceticus and midas_g_1240 in acetoclastic methanogenesis\n",
    "\n",
    "# (1) Filter and extract species\n",
    "sub_syntrophaceticus = df[(df['genus'] == 'Syntrophaceticus') & (df['function'] == 'METH-ACETATE-PWY')].copy()\n",
    "sub_syntrophaceticus['taxon_function_abun'] = pd.to_numeric(sub_syntrophaceticus['taxon_function_abun'], errors='coerce').fillna(0)\n",
    "sub_syntrophaceticus['species'] = (sub_syntrophaceticus['taxonomy'].astype(str)\n",
    "                  .str.extract(r\"s__\\s*([^;]+)\", expand=False)\n",
    "                  .fillna('unclassified').str.strip())\n",
    "\n",
    "sub_midas_g_1240 = df[(df['genus'] == 'midas_g_1240') & (df['function'] == 'METH-ACETATE-PWY')].copy()\n",
    "sub_midas_g_1240['taxon_function_abun'] = pd.to_numeric(sub_midas_g_1240['taxon_function_abun'], errors='coerce').fillna(0)\n",
    "sub_midas_g_1240['species'] = (sub_midas_g_1240['taxonomy'].astype(str)\n",
    "                  .str.extract(r\"s__\\s*([^;]+)\", expand=False)\n",
    "                  .fillna('unclassified').str.strip())\n",
    "\n",
    "\n",
    "# (2) Per-species sums\n",
    "df_pr1_syntrophaceticus = (sub_syntrophaceticus[sub_syntrophaceticus['sample'].isin(PR1)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR1'}))\n",
    "df_pr4_syntrophaceticus = (sub_syntrophaceticus[sub_syntrophaceticus['sample'].isin(PR4)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR4'}))\n",
    "\n",
    "df_pr1_midas_g_1240 = (sub_midas_g_1240[sub_midas_g_1240['sample'].isin(PR1)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR1'}))\n",
    "df_pr4_midas_g_1240 = (sub_midas_g_1240[sub_midas_g_1240['sample'].isin(PR4)]\n",
    "          .groupby('species', as_index=False)['taxon_function_abun']\n",
    "          .sum().rename(columns={'taxon_function_abun':'species_contribution_PR4'}))\n",
    "\n",
    "# (3) Merge and prepare\n",
    "merged_syntrophaceticus = pd.merge(df_pr1_syntrophaceticus, df_pr4_syntrophaceticus, on='species', how='outer').fillna(0)\n",
    "merged_syntrophaceticus['total'] = merged_syntrophaceticus['species_contribution_PR1'] + merged_syntrophaceticus['species_contribution_PR4']\n",
    "\n",
    "merged_midas_g_1240 = pd.merge(df_pr1_midas_g_1240, df_pr4_midas_g_1240, on='species', how='outer').fillna(0)\n",
    "merged_midas_g_1240['total'] = merged_midas_g_1240['species_contribution_PR1'] + merged_midas_g_1240['species_contribution_PR4']\n",
    "\n",
    "# (4) Plot\n",
    "x = merged_syntrophaceticus['species_contribution_PR1'].to_numpy()\n",
    "y = merged_syntrophaceticus['species_contribution_PR4'].to_numpy()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x, y, alpha=0.6, s=30)\n",
    "m = float(np.nanmax(np.r_[x, y, 1e-12]))\n",
    "plt.plot([0, m], [0, m], 'k--', linewidth=1)\n",
    "\n",
    "# Label top 3 species by total contribution\n",
    "top3_syntrophaceticus = merged_syntrophaceticus.nlargest(3, 'total')\n",
    "for _, row in top3_syntrophaceticus.iterrows():\n",
    "    plt.text(row['species_contribution_PR1'], row['species_contribution_PR4'],\n",
    "             row['species'], fontsize=9, alpha=0.8, ha='left', va='bottom')\n",
    "\n",
    "plt.xlabel('PR1 species contribution')\n",
    "plt.ylabel('PR4 species contribution')\n",
    "plt.title('Species-level METH-ACETATE: PR1 vs PR4 (Syntrophaceticus)')\n",
    "plt.axis('equal'); plt.xlim(0, m); plt.ylim(0, m)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "x = merged_midas_g_1240['species_contribution_PR1'].to_numpy()\n",
    "y = merged_midas_g_1240['species_contribution_PR4'].to_numpy()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(x, y, alpha=0.6, s=30)\n",
    "m = float(np.nanmax(np.r_[x, y, 1e-12]))\n",
    "plt.plot([0, m], [0, m], 'k--', linewidth=1)\n",
    "\n",
    "# Label top 3 species by total contribution\n",
    "top3_midas_g_1240 = merged_midas_g_1240.nlargest(3, 'total')\n",
    "for _, row in top3_midas_g_1240.iterrows():\n",
    "    plt.text(row['species_contribution_PR1'], row['species_contribution_PR4'],\n",
    "             row['species'], fontsize=9, alpha=0.8, ha='left', va='bottom')\n",
    "\n",
    "plt.xlabel('PR1 species contribution')\n",
    "plt.ylabel('PR4 species contribution')\n",
    "plt.title('Species-level METH-ACETATE-PWY: PR1 vs PR4 (midas_g_1240)')\n",
    "plt.axis('equal'); plt.xlim(0, m); plt.ylim(0, m)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Time-series pathway abundance\n",
    "\n",
    "# (1) Merging data\n",
    "df = df_path_abun.merge(df_meta, left_on='sample', right_on='Barcode', how='left').copy()\n",
    "\n",
    "\n",
    "# (2) Numeric values\n",
    "df['taxon_function_abun'] = pd.to_numeric(df['taxon_function_abun'], errors='coerce').fillna(0)\n",
    "\n",
    "\n",
    "# (3) Convert date to datetime format\n",
    "df['SampleDate'] = pd.to_datetime(df['SampleDate'], format='%m/%d/%Y').copy()\n",
    "\n",
    "\n",
    "# (4) Collapse to sample (instead of ASV)\n",
    "df_col = (\n",
    "    df\n",
    "    .groupby(['sample', 'function'], as_index=False)\n",
    "    .agg(\n",
    "        function_abun=('taxon_function_abun', 'sum'),\n",
    "        SampleDate=('SampleDate', 'first'),\n",
    "        ReactorID=('ReactorID', 'first')\n",
    "    )\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "\n",
    "# Add date column to df_col\n",
    "#df_col = df_col.merge(df[['sample', 'SampleDate']], on='sample', how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11297a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investigate discrepancy between collapsed stratified and unstratified results\n",
    "\n",
    "\n",
    "# (1) Collapse stratified table to sample × pathway totals\n",
    "df_path_abun = df_path_abun.copy()\n",
    "df_path_abun[\"taxon_function_abun\"] = pd.to_numeric(df_path_abun[\"taxon_function_abun\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "pathway_abundance = (\n",
    "    df_path_abun.groupby([\"sample\", \"function\"], as_index=False)[\"taxon_function_abun\"]\n",
    "                .sum()\n",
    "                .rename(columns={\"taxon_function_abun\": \"pathway_abundance_collapsed\"})\n",
    ")\n",
    "\n",
    "\n",
    "# (2) Unstratified table: wide → long (sample × pathway), ensure numeric\n",
    "u = df_path_abun_unstrat.copy()\n",
    "\n",
    "# Detect pathway ID column\n",
    "if \"function\" in u.columns:\n",
    "    id_col = \"function\"\n",
    "elif \"pathway\" in u.columns:\n",
    "    id_col = \"pathway\"\n",
    "else:\n",
    "    id_col = u.columns[0]  # fallback: first column is the pathway ID\n",
    "\n",
    "u = u.rename(columns={id_col: \"function\"})\n",
    "\n",
    "un_long = (\n",
    "    u.melt(id_vars=[\"function\"], var_name=\"sample\", value_name=\"pathway_abundance_unstrat\")\n",
    ")\n",
    "un_long[\"sample\"] = un_long[\"sample\"].astype(str).str.strip()\n",
    "un_long[\"function\"] = un_long[\"function\"].astype(str).str.strip()\n",
    "un_long[\"pathway_abundance_unstrat\"] = pd.to_numeric(\n",
    "    un_long[\"pathway_abundance_unstrat\"], errors=\"coerce\"\n",
    ").fillna(0)\n",
    "\n",
    "\n",
    "# (3) Align keys and merge collapsed vs unstratified\n",
    "pathway_abundance[\"sample\"] = pathway_abundance[\"sample\"].astype(str).str.strip()\n",
    "pathway_abundance[\"function\"] = pathway_abundance[\"function\"].astype(str).str.strip()\n",
    "\n",
    "merged_comp = pathway_abundance.merge(un_long, on=[\"sample\", \"function\"], how=\"inner\")\n",
    "\n",
    "\n",
    "# (4) Compute differences (protect against division by ~0)\n",
    "eps = 1e-12\n",
    "merged_comp[\"difference\"] = (\n",
    "    merged_comp[\"pathway_abundance_unstrat\"] - merged_comp[\"pathway_abundance_collapsed\"]\n",
    ")\n",
    "merged_comp[\"relative_diff_%\"] = (\n",
    "    merged_comp[\"difference\"] / (merged_comp[\"pathway_abundance_collapsed\"] + eps) * 100\n",
    ")\n",
    "# Optional: log2 fold change (numerically stable)\n",
    "# merged_comp[\"log2_fold\"] = np.log2(\n",
    "#     (merged_comp[\"pathway_abundance_unstrat\"] + eps) / (merged_comp[\"pathway_abundance_collapsed\"] + eps)\n",
    "# )\n",
    "\n",
    "\n",
    "# (5) Attach reactor metadata (style variable for plotting)\n",
    "meta = df_meta.copy()\n",
    "meta.columns = meta.columns.str.strip()\n",
    "\n",
    "# (6) Normalize barcode column to 'sample'\n",
    "if \"Barcode\" in meta.columns:\n",
    "    barcode_col = \"Barcode\"\n",
    "elif \"Barcode \" in meta.columns:\n",
    "    barcode_col = \"Barcode \"\n",
    "else:\n",
    "    raise ValueError(\"df_meta must contain 'Barcode' (or 'Barcode ').\")\n",
    "\n",
    "meta = meta.rename(columns={barcode_col: \"sample\"})\n",
    "meta[\"sample\"] = meta[\"sample\"].astype(str).str.strip()\n",
    "meta[\"ReactorID\"] = meta[\"ReactorID\"].astype(str).str.strip()\n",
    "\n",
    "merged_comp = merged_comp.merge(meta[[\"sample\", \"ReactorID\"]], on=\"sample\", how=\"left\")\n",
    "\n",
    "\n",
    "# (7) Scatterplot: collapsed vs unstratified with 1:1 line\n",
    "plt.figure(figsize=(6.5, 6))\n",
    "sns.scatterplot(\n",
    "    data=merged_comp,\n",
    "    x=\"pathway_abundance_unstrat\",\n",
    "    y=\"pathway_abundance_collapsed\",\n",
    "    hue=\"sample\",\n",
    "    style=\"ReactorID\",\n",
    "    s=60,\n",
    "    alpha=0.85\n",
    ")\n",
    "\n",
    "m = merged_comp[[\"pathway_abundance_unstrat\", \"pathway_abundance_collapsed\"]].to_numpy().max()\n",
    "plt.plot([0, m], [0, m], \"k--\", lw=1)\n",
    "\n",
    "plt.xlabel(\"Unstratified pathway abundance\")\n",
    "plt.ylabel(\"Collapsed stratified pathway abundance\")\n",
    "plt.title(\"Agreement between unstratified and collapsed stratified pathway abundances\")\n",
    "plt.legend(title=\"Sample / ReactorID\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc97954",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scatterplot: agreement between collapsed stratified and unstratified pathway abundances\n",
    "\n",
    "\n",
    "# (0) Define pathway of interest\n",
    "PATH = \"METH-ACETATE-PWY\"\n",
    "\n",
    "\n",
    "# (1) Stratified table → collapse to per-sample × per-function totals\n",
    "df_strat = df_path_abun[['sample', 'function', 'taxon_function_abun']].copy()\n",
    "df_strat['taxon_function_abun'] = pd.to_numeric(df_strat['taxon_function_abun'], errors='coerce').fillna(0)\n",
    "df_strat = (df_strat\n",
    "            .groupby(['sample','function'], as_index=False)['taxon_function_abun']\n",
    "            .sum()\n",
    "            .rename(columns={'taxon_function_abun':'from_strat'}))\n",
    "\n",
    "# Normalise join keys (trim + uppercase) to ensure alignment with unstratified table headers\n",
    "for c in ['sample','function']:\n",
    "    df_strat[c] = df_strat[c].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Capture the set of samples actually present after collapsing to filter the unstratified table\n",
    "samples = pd.Index(df_strat['sample'].unique())\n",
    "\n",
    "\n",
    "# (2) Unstratified table (wide) → long (sample × function value)\n",
    "df_un = df_path_abun_unstrat.copy()\n",
    "df_un.columns = [c.strip().upper() for c in df_un.columns]\n",
    "id_col = 'FUNCTION' if 'FUNCTION' in df_un.columns else ('PATHWAY' if 'PATHWAY' in df_un.columns else None)\n",
    "if id_col is None:\n",
    "    raise ValueError(\"Could not find function/pathway id column in unstratified table.\")\n",
    "\n",
    "keep = [id_col] + [c for c in df_un.columns if c in samples]\n",
    "df_un = df_un[keep].copy()\n",
    "\n",
    "# Melt to long format, normalise keys, coerce values to numeric\n",
    "un_long = (df_un\n",
    "           .melt(id_vars=[id_col], var_name='sample', value_name='from_unstrat')\n",
    "           .rename(columns={id_col: 'function'}))\n",
    "for c in ['sample','function']:\n",
    "    un_long[c] = un_long[c].astype(str).str.strip().str.upper()\n",
    "un_long['from_unstrat'] = pd.to_numeric(\n",
    "    un_long['from_unstrat'].astype(str).str.replace(',', '', regex=False),\n",
    "    errors='coerce'\n",
    ").fillna(0)\n",
    "\n",
    "\n",
    "# (3) Merge paired measurements and compute diagnostics\n",
    "cmp = df_strat.merge(un_long, on=['sample','function'], how='outer')\n",
    "cmp['from_strat']   = pd.to_numeric(cmp['from_strat'], errors='coerce').fillna(0)\n",
    "cmp['from_unstrat'] = pd.to_numeric(cmp['from_unstrat'], errors='coerce').fillna(0)\n",
    "\n",
    "# Differences: absolute (for magnitude) and relative (scale-aware; NaN when unstrat is zero)\n",
    "cmp['abs_diff'] = (cmp['from_strat'] - cmp['from_unstrat']).abs()\n",
    "cmp['rel_diff'] = np.where(cmp['from_unstrat'] > 0,\n",
    "                           cmp['abs_diff'] / cmp['from_unstrat'].abs(),\n",
    "                           np.nan)\n",
    "\n",
    "# Optional: restrict to a single pathway; then keep rows measured in at least one source\n",
    "plot_df = cmp if PATH is None else cmp[cmp['function'] == PATH].copy()\n",
    "mask = (plot_df['from_strat'] > 0) | (plot_df['from_unstrat'] > 0)\n",
    "plot_df = plot_df[mask]\n",
    "\n",
    "# Summary agreement metrics for the plotted pairs\n",
    "n_pairs = len(plot_df)\n",
    "pearson = (np.corrcoef(plot_df['from_unstrat'], plot_df['from_strat'])[0,1]\n",
    "           if n_pairs >= 2 else np.nan)\n",
    "mae  = float(np.nanmean(plot_df['abs_diff']))\n",
    "mape = float(np.nanmean(plot_df['rel_diff']) * 100)\n",
    "\n",
    "print(f\"Compared pairs: {n_pairs}\")\n",
    "print(f\"Pearson r: {pearson:.3f} | MAE: {mae:.3g} | MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Quick sanity checks to spot join/key issues across sources.\n",
    "print(\"Unmatched functions (strat-only):\", len(set(df_strat['function']) - set(un_long['function'])))\n",
    "print(\"Unmatched functions (unstrat-only):\", len(set(un_long['function']) - set(df_strat['function'])))\n",
    "print(\"Unmatched samples (strat-only):\", len(set(df_strat['sample']) - set(un_long['sample'])))\n",
    "print(\"Unmatched samples (unstrat-only):\", len(set(un_long['sample']) - set(df_strat['sample'])))\n",
    "\n",
    "\n",
    "# (4) Scatter plot: collapsed stratified vs unstratified per-sample abundance\n",
    "x = plot_df['from_unstrat'].to_numpy()\n",
    "y = plot_df['from_strat'].to_numpy()\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=120, constrained_layout=True)\n",
    "ax.scatter(x, y, alpha=0.6, s=18)\n",
    "\n",
    "m = float(np.nanmax(np.concatenate([np.nan_to_num(x), np.nan_to_num(y), [1]])))\n",
    "ax.plot([0, m], [0, m], 'k--', linewidth=1)\n",
    "title = 'All functions' if PATH is None else PATH\n",
    "ax.set_title(f'Stratified (collapsed) vs Unstratified — {title}')\n",
    "ax.set_xlabel('Unstratified per-sample abundance')\n",
    "ax.set_ylabel('Collapsed-from-stratified per-sample abundance')\n",
    "ax.set_xlim(0, m); ax.set_ylim(0, m); ax.set_aspect('equal', adjustable='box')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Per-pathway median relative difference barplot\n",
    "\n",
    "\n",
    "# (1) Clean input: ensure numeric, drop inf/NaN\n",
    "merged_comp = merged_comp.copy()\n",
    "merged_comp[\"relative_diff_%\"] = pd.to_numeric(merged_comp[\"relative_diff_%\"], errors=\"coerce\")\n",
    "merged_comp = merged_comp.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"relative_diff_%\"])\n",
    "\n",
    "# (2) Aggregate per pathway: median relative difference + sample count\n",
    "agg = (\n",
    "    merged_comp.groupby(\"function\", as_index=False)[\"relative_diff_%\"]\n",
    "               .agg(median_rel_diff_pct=\"median\", n=\"count\")\n",
    ")\n",
    "\n",
    "# (3) Order pathways by absolute median difference (largest first)\n",
    "agg = agg.reindex(agg[\"median_rel_diff_pct\"].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# (4) Barplot (symlog y-scale to preserve sign, compress extremes)\n",
    "plt.figure(figsize=(8, 7))\n",
    "bars = plt.bar(agg[\"function\"], agg[\"median_rel_diff_pct\"], color=\"steelblue\", alpha=0.9)\n",
    "plt.axhline(0, color=\"k\", lw=1)\n",
    "plt.yscale(\"symlog\", linthresh=1)   # linear near 0, log elsewhere\n",
    "\n",
    "# (4.5) Add horizontal translucent percentage guide lines (log-spaced)\n",
    "ymax = np.nanmax(np.abs(agg[\"median_rel_diff_pct\"]))\n",
    "guide_levels = np.logspace(0, np.ceil(np.log10(ymax)), num=int(np.ceil(np.log10(ymax))) + 1, base=10)\n",
    "\n",
    "for val in guide_levels:\n",
    "    # Positive lines (all)\n",
    "    plt.axhline(val, color=\"grey\", linestyle=\"--\", lw=0.7, alpha=0.3, zorder=0)\n",
    "    plt.text(len(agg) - 0.3, val, f\"{val:,.0f}%\", color=\"grey\", alpha=0.6,\n",
    "             va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "    # Negative lines (only below -10)\n",
    "    if val >= 10:\n",
    "        plt.axhline(-val, color=\"grey\", linestyle=\"--\", lw=0.7, alpha=0.3, zorder=0)\n",
    "        plt.text(len(agg) - 0.3, -val, f\"-{val:,.0f}%\", color=\"grey\", alpha=0.6,\n",
    "                 va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "# (5) Labels, title, and layout\n",
    "plt.ylabel(\"Median relative difference (%)  [symlog]\")\n",
    "plt.xlabel(\"Pathway (MetaCyc ID)\")\n",
    "plt.title(\"Collapsed vs unstratified: per-pathway median relative difference\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da00ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Top 25 pathways with median relative difference (%)\n",
    "\n",
    "top25 = agg.reindex(agg[\"median_rel_diff_pct\"].abs().sort_values(ascending=False).index).head(25)\n",
    "\n",
    "print(top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pathway abundance over time in PR1 and PR4\n",
    "\n",
    "\n",
    "# (0) Config: pathways to plot (case-insensitive after normalization below)\n",
    "PATHS = {\"METHANOGENESIS-PWY\", \"METH-ACETATE-PWY\"}\n",
    "\n",
    "\n",
    "# (1) Clean metadata: standardize names, restrict to PR1/PR4, parse dates\n",
    "dfm = df_meta.copy()\n",
    "dfm.columns = dfm.columns.str.strip()\n",
    "\n",
    "# Normalize sample/barcode column name to 'sample'\n",
    "barcode_col = \"Barcode\" if \"Barcode\" in dfm.columns else (\"Barcode \" if \"Barcode \" in dfm.columns else None)\n",
    "if barcode_col is None:\n",
    "    raise ValueError(\"df_meta must contain a 'Barcode' (or 'Barcode ') column.\")\n",
    "dfm = dfm.rename(columns={barcode_col: \"sample\"})\n",
    "\n",
    "# String-clean and parse\n",
    "dfm[\"sample\"] = dfm[\"sample\"].astype(str).str.strip().str.upper()\n",
    "dfm[\"ReactorID\"] = dfm[\"ReactorID\"].astype(str).str.strip().str.upper()\n",
    "dfm[\"SampleDate\"] = pd.to_datetime(dfm[\"SampleDate\"], errors=\"coerce\")\n",
    "\n",
    "# Keep only PR1/PR4 rows with valid dates\n",
    "dfm = dfm[dfm[\"ReactorID\"].isin([\"PR1\", \"PR4\"])].copy()\n",
    "dfm = dfm.dropna(subset=[\"SampleDate\"])\n",
    "\n",
    "\n",
    "# (2) Unstratified pathway table: normalize headers, select usable samples, melt to long\n",
    "u = df_path_abun_unstrat.copy()\n",
    "u.columns = [c.strip().upper() for c in u.columns]\n",
    "\n",
    "# Detect pathway ID column (after uppercasing)\n",
    "id_col = \"FUNCTION\" if \"FUNCTION\" in u.columns else (\"PATHWAY\" if \"PATHWAY\" in u.columns else None)\n",
    "if id_col is None:\n",
    "    raise ValueError(\"Unstratified table needs an ID column named 'function' or 'pathway' (any case).\")\n",
    "\n",
    "# Keep only pathway column + samples present in metadata subset\n",
    "keep_samples = set(dfm[\"sample\"])\n",
    "keep_cols = [id_col] + [c for c in u.columns if c in keep_samples]\n",
    "u = u[keep_cols].copy()\n",
    "\n",
    "# Long format and clean types\n",
    "long_u = (\n",
    "    u.melt(id_vars=[id_col], var_name=\"sample\", value_name=\"abun\")\n",
    "     .rename(columns={id_col: \"function\"})\n",
    ")\n",
    "long_u[\"sample\"] = long_u[\"sample\"].astype(str).str.strip().str.upper()\n",
    "long_u[\"function\"] = long_u[\"function\"].astype(str).str.strip().str.upper()\n",
    "long_u[\"abun\"] = pd.to_numeric(long_u[\"abun\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "\n",
    "# (3) Attach metadata and filter to target pathways and reactors\n",
    "sub = (\n",
    "    long_u.merge(dfm[[\"sample\", \"SampleDate\", \"ReactorID\"]], on=\"sample\", how=\"inner\")\n",
    "          .query(\"function in @PATHS and ReactorID in ['PR1','PR4']\")\n",
    ")\n",
    "\n",
    "\n",
    "# (4) Aggregate per date × reactor × pathway (sum across replicates if any)\n",
    "ts = (\n",
    "    sub.groupby([\"SampleDate\", \"ReactorID\", \"function\"], as_index=False)[\"abun\"]\n",
    "       .sum()\n",
    "       .sort_values([\"function\", \"SampleDate\", \"ReactorID\"])\n",
    ")\n",
    "\n",
    "\n",
    "# (5) Plot: one panel per pathway; lines for PR1 vs PR4\n",
    "paths_sorted = sorted(PATHS)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(paths_sorted), ncols=1, figsize=(8, 3.2 * len(paths_sorted)), dpi=120, constrained_layout=True\n",
    ")\n",
    "if len(paths_sorted) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, pw in zip(axes, paths_sorted):\n",
    "    g = ts[ts[\"function\"] == pw]\n",
    "    for rid, gg in g.groupby(\"ReactorID\", sort=False):\n",
    "        ax.plot(gg[\"SampleDate\"], gg[\"abun\"], marker=\"o\", linewidth=1.5, markersize=3, label=rid)\n",
    "    ax.set_title(f\"{pw} — PR1 vs PR4 over time\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Pathway abundance\")\n",
    "    ax.grid(True, linewidth=0.4, alpha=0.5)\n",
    "    ax.legend(frameon=False, ncol=2)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# (6) Optional: table of PR1/PR4 values and their difference per date × pathway\n",
    "wide = (\n",
    "    ts.pivot_table(index=[\"SampleDate\", \"function\"], columns=\"ReactorID\", values=\"abun\", fill_value=0)\n",
    "      .assign(DIFF=lambda d: d.get(\"PR4\", 0) - d.get(\"PR1\", 0))\n",
    "      .sort_index()\n",
    ")\n",
    "print(wide.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Select required columns from stratified pathway contributions\n",
    "df = df_path_abun[[\"sample\", \"function\", \"taxon\", \"taxon_function_abun\"]].copy()\n",
    "\n",
    "# (2) Attach taxonomy to ASVs\n",
    "df = df.merge(df_tax[[\"taxon\", \"taxonomy\"]], on=\"taxon\", how=\"left\")\n",
    "\n",
    "# (3) Attach reactor + date metadata; keep only desired barcodes\n",
    "meta = (df_meta.loc[df_meta[\"Barcode\"].isin(barcodes), [\"Barcode\", \"ReactorID\", \"SampleDate\"]]\n",
    "              .rename(columns={\"Barcode\": \"sample\"}))\n",
    "df = df.merge(meta, on=\"sample\", how=\"inner\")\n",
    "\n",
    "# (4) Parse dates and extract genus from taxonomy\n",
    "df[\"SampleDate\"] = pd.to_datetime(df[\"SampleDate\"], errors=\"coerce\")\n",
    "df[\"genus\"] = (df[\"taxonomy\"].astype(str)\n",
    "               .str.extract(r\"g__\\s*([^;]+)\", expand=False)\n",
    "               .str.strip()\n",
    "               .fillna(\"Unclassified\"))\n",
    "\n",
    "# (5) Ensure numeric abundances\n",
    "df[\"taxon_function_abun\"] = pd.to_numeric(df[\"taxon_function_abun\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# (6) Collapse ASV → genus per (pathway × reactor × date)\n",
    "df_col = (df.groupby([\"function\", \"genus\", \"ReactorID\", \"SampleDate\"], as_index=False)[\"taxon_function_abun\"]\n",
    "            .sum()\n",
    "            .rename(columns={\"taxon_function_abun\": \"genus_contribution\"}))\n",
    "\n",
    "# (7) Filter to selected pathways (e.g., two methanogenesis routes)\n",
    "df_col = df_col[df_col[\"function\"].isin(pathways)].copy()\n",
    "\n",
    "# (8) Thresholding: keep genera with sufficient total signal and temporal support\n",
    "min_total = 3000        # minimal summed contribution across all dates (per reactor × pathway × genus)\n",
    "min_nonzero_dates = 2   # require ≥ this many dates with non-zero contribution\n",
    "tot = (df_col.groupby([\"ReactorID\", \"function\", \"genus\"])[\"genus_contribution\"].transform(\"sum\"))\n",
    "nz  = (df_col.groupby([\"ReactorID\", \"function\", \"genus\"])[\"genus_contribution\"].transform(lambda s: (s > 0).sum()))\n",
    "df_plot = df_col[(tot >= min_total) & (nz >= min_nonzero_dates)].copy()\n",
    "\n",
    "# (9) Time-series plot: per-pathway panels; color = genus, line style = reactor\n",
    "g = sns.relplot(\n",
    "    data=df_plot,\n",
    "    x=\"SampleDate\",\n",
    "    y=\"genus_contribution\",\n",
    "    hue=\"genus\",\n",
    "    style=\"ReactorID\",\n",
    "    col=\"function\",\n",
    "    kind=\"line\",\n",
    "    errorbar=None,\n",
    "    height=4, aspect=1.1,\n",
    "    facet_kws={\"sharex\": True, \"sharey\": False}\n",
    ")\n",
    "\n",
    "g.set_axis_labels(\"Sampling date\", \"Genus contribution to pathway abundance\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.fig.suptitle(\n",
    "    \"Genus-level contributions over time (filtered: total ≥ 3000 & ≥2 non-zero dates)\",\n",
    "    fontsize=11, y=1.03\n",
    ")\n",
    "# Move legend outside and set a single concise title\n",
    "leg = g._legend\n",
    "if leg is not None:\n",
    "    leg.set_bbox_to_anchor((1.05, 1))\n",
    "    leg.set_title(\"Genus / ReactorID\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assessment of taxonomic richness as time-series (genus-level)\n",
    "\n",
    "\n",
    "\n",
    "# (1) Load ASV abundance, keep only ASV ID and selected barcodes\n",
    "path_seqtab = (\n",
    "    \"~/Thesis/data/picrust2_testruns/2.5.3/picrust2_stratified/\"\n",
    "    \"picrust2_out_pipeline_stratified_lasse/EC_metagenome_out/seqtab_norm.tsv\"\n",
    ")\n",
    "\n",
    "# Read header to detect the ASV ID column name (e.g. 'feature_id')\n",
    "hdr = pd.read_csv(path_seqtab, sep=\"\\t\", nrows=0)\n",
    "id_col = hdr.columns[0]\n",
    "\n",
    "usecols = [id_col] + barcodes\n",
    "df_seq = pd.read_csv(path_seqtab, sep=\"\\t\", usecols=usecols, dtype=str)\n",
    "\n",
    "# Standardise ASV ID column name to 'taxon'\n",
    "df_seq = df_seq.rename(columns={id_col: \"taxon\"})\n",
    "\n",
    "# Ensure numeric abundances; non-parsable values → 0\n",
    "df_seq[barcodes] = df_seq[barcodes].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "\n",
    "# (2) Map ASV to genus based on taxonomy table\n",
    "tax = df_tax[[\"taxon\", \"taxonomy\"]].copy()\n",
    "tax[\"genus\"] = (\n",
    "    tax[\"taxonomy\"].astype(str)\n",
    "       .str.extract(r\"g__\\s*([^;]+)\", expand=False)\n",
    "       .str.strip()\n",
    "       .replace({\"\": np.nan})\n",
    "       .fillna(\"Unclassified\")\n",
    ")\n",
    "\n",
    "# Join genus annotation onto ASV abundance table\n",
    "dfm = df_seq.merge(tax[[\"taxon\", \"genus\"]], on=\"taxon\", how=\"left\")\n",
    "dfm[\"genus\"] = dfm[\"genus\"].fillna(\"Unclassified\")\n",
    "\n",
    "\n",
    "# (3) Convert to long format and collapse ASVs → genus per sample\n",
    "long = dfm.melt(id_vars=[\"taxon\", \"genus\"], var_name=\"sample\", value_name=\"abun\")\n",
    "genus_long = long.groupby([\"genus\", \"sample\"], as_index=False)[\"abun\"].sum()\n",
    "\n",
    "# Optional: wide genus × samples matrix (useful for ordination or export)\n",
    "genus_wide = genus_long.pivot(index=\"genus\", columns=\"sample\", values=\"abun\").fillna(0)\n",
    "\n",
    "\n",
    "# (4) Compute taxonomic richness (number of genera with abun > 0 per sample)\n",
    "richness = (\n",
    "    genus_long.loc[genus_long[\"abun\"] > 0]\n",
    "              .groupby(\"sample\")[\"genus\"]\n",
    "              .nunique()\n",
    "              .reset_index(name=\"richness\")\n",
    ")\n",
    "\n",
    "\n",
    "# (5) Attach reactor and sampling metadata\n",
    "df_meta = df_meta.copy()\n",
    "df_meta.columns = df_meta.columns.str.strip()\n",
    "df_meta[\"Barcode\"] = df_meta[\"Barcode\"].astype(str).str.strip()\n",
    "df_meta[\"ReactorID\"] = df_meta[\"ReactorID\"].astype(str).str.strip()\n",
    "df_meta[\"SampleDate\"] = pd.to_datetime(df_meta[\"SampleDate\"], errors=\"coerce\")\n",
    "\n",
    "richness = richness.merge(\n",
    "    df_meta[[\"Barcode\", \"ReactorID\", \"SampleDate\"]],\n",
    "    left_on=\"sample\",\n",
    "    right_on=\"Barcode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# (6) Visualise taxonomic richness over time per setup\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=richness,\n",
    "    x=\"SampleDate\",\n",
    "    y=\"richness\",\n",
    "    hue=\"ReactorID\",\n",
    "    errorbar=None\n",
    ")\n",
    "plt.xlabel(\"Sampling date\")\n",
    "plt.ylabel(\"Genus richness (abundance > 0)\")\n",
    "plt.title(\"Taxonomic richness over time by setup\")\n",
    "plt.legend(title=\"ReactorID\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
